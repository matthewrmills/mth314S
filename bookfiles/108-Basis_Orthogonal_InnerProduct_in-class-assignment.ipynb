{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 108 In-Class Assignment: Change of Basis, Projections, Inner Products\n",
    "\n",
    "<img alt=\"Graph showing how one vector can be projected onto another vector by forming a right triangle\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/98/Projection_and_rejection.png\" width=\"50%\">\n",
    "\n",
    "Image from: https://en.wikipedia.org/wiki/Vector_projection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda for today's class\n",
    "\n",
    "1. [Change of Basis](#CoB)\n",
    "1. [Understanding Projections with Code](#Understanding_Projections_with_Code)\n",
    "1. [Gram-Schmidt Orthoganalization Process](#Gram-Schmidt_Orthoganalization_Process)\n",
    "1. [Subspace Projections](#subspace)\n",
    "1. [The Orthogonal Decomposition Theorem](#orthog_decomp)\n",
    "1. [Inner Products and Matrices](#innerP)\n",
    "1. [Function Approximation](#Function_Approximation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"CoB\"></a>\n",
    "# 1.Change of Basis\n",
    "\n",
    "Here is a quick test to see if you understand how to change coordinate systems for vector spaces. We won't spend a lot of time this semester on this concept, but it is a good question for a quiz/exam. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION:</font>** Given the basis $S$ for $\\mathbb{R}^3$,\n",
    "$$S = \\{(2,-1,-1), (0,1,3), (1,1,1)\\},$$\n",
    "\n",
    "Find the coordinate vector of $u=(1,-4,-5)$ relative to the given basis $S$. Store this coordinate in a variable ```ub``` for checking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##work here\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.vector(ub,\"91cc7b39126e04b42501804cc9ef7d83\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>QUESTION:</font>** Given two bases $S$ and $S'$ in $\\mathbb{R}^3$,\n",
    "$$S = \\{(2,-1,-1), (0,1,3), (1,1,1)\\},$$\n",
    "$$S' = \\{(1,4,7), (2,5,8), (3,6,10)\\},$$\n",
    "Find the transition matrix $T$ that will take points in the $S$ coordinate representation and put them into $S'$ coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##work here\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.matrix(T,\"d467bed81305d1623528055cd63e8194\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name=\"Understanding_Projections_with_Code\"></a>\n",
    "# 2. Understanding Projections With Code\n",
    "\n",
    "In this in-class assignment, we are going to avoid some of the more advanced libraries ((i.e. no ```numpy``` or ```scipy``` or ```sympy```) to try to get a better understanding about what is going on in the math. \n",
    "The following code implements some common linear algebra functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Python Libraries only\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(u,v):\n",
    "    '''Calculate the dot product between vectors u and v'''\n",
    "    temp = 0;\n",
    "    for i in range(len(u)):\n",
    "        temp += u[i]*v[i]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(m1,m2):\n",
    "    '''Calculate the matrix multiplication between m1 and m2 represented as list-of-list.'''\n",
    "    n = len(m1)\n",
    "    d = len(m2)\n",
    "    m = len(m2[0])\n",
    "    \n",
    "    if len(m1[0]) != d:\n",
    "        print(\"ERROR - inner dimentions not equal\")\n",
    "    result = [[0 for i in range(n)] for j in range(m)]\n",
    "    for i in range(0,n):\n",
    "        for j in range(0,m):\n",
    "            for k in range(0,d):\n",
    "                result[i][j] = result[i][j] + m1[i][k] * m2[k][j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vectors(v1,v2):\n",
    "    v3 = []\n",
    "    for i in range(len(v1)):\n",
    "        v3.append(v1[i]+v2[i])\n",
    "    return v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_vectors(v1,v2):\n",
    "    v3 = []\n",
    "    for i in range(len(v1)):\n",
    "        v3.append(v1[i]-v2[i])\n",
    "    return v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(u):\n",
    "    '''Calculate the norm of vector u'''\n",
    "    nm = 0\n",
    "    for i in range(len(u)):\n",
    "        nm += u[i]*u[i]\n",
    "    return math.sqrt(nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(A):\n",
    "    '''Calculate the transpose of matrix A represented as list of lists'''\n",
    "    n = len(A)\n",
    "    m = len(A[0])\n",
    "    AT = list()\n",
    "    for j in range(0,m):    \n",
    "        temp = list()\n",
    "        for i in range(0,n):\n",
    "            temp.append(A[i][j])\n",
    "        AT.append(temp)\n",
    "    return AT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection function\n",
    "\n",
    "&#9989; **<font color=red>DO THIS:</font>** Write a function that projects vector $v$ onto vector $u$. \n",
    "Do not use the numpy library. \n",
    "Instead use the functions provided above:\n",
    "\n",
    "$$\\mbox{proj}_u v = \\frac{v \\cdot u}{u \\cdot u} u$$\n",
    "\n",
    "Make sure this function will work for any size of $v$ and $u$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(v,u):\n",
    "    ## Put your code here\n",
    "    return pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test your function. Below are two example vectors. Make sure you get the correct answers. \n",
    "You may want to test this code with more than one set of vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = [1,2,0,3]\n",
    "v = [4,0,5,8]\n",
    "print(proj(u,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "\n",
    "checkanswer.vector(proj(u,v),'53216508af49c616fa0f4e9676ce3b9d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing projections\n",
    "\n",
    "&#9989; **<font color=red>DO THIS:</font>**See if you can design and implement a small function that takes two vectors ($a$ and $b$) as inputs and generates a figure similar to the one above.\n",
    "\n",
    "\n",
    "I.e. a black line from the origin to \"$b$\", a black line from origin to \"$a$\"; a green line showing the \"$a$\" component in the \"$b$\" direction and a red line showing the \"$a$\" component orthogonal to the green line. \n",
    "Also see section titled \"Projection of One Vector onto Another Vector\" in Section 4.6 on page 258 of the book.\n",
    "\n",
    "When complete, show your solution to the instructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "b = [3,2]\n",
    "a = [2,3]\n",
    "\n",
    "def show_projection(a,b):\n",
    "    plt.plot([0,a[0]], [0,a[1]], color='black')\n",
    "    plt.annotate('b', b, \n",
    "            xytext=(0.9, 0.7), textcoords='axes fraction',\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "            horizontalalignment='right', verticalalignment='top')\n",
    "    plt.annotate('a', a, \n",
    "            xytext=(0.7, 0.95), textcoords='axes fraction',\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "            horizontalalignment='right', verticalalignment='top')\n",
    "    plt.plot([0,b[0]], [0,b[1]], color='black')\n",
    "    \n",
    "#Finish your code here\n",
    "\n",
    "    plt.axis('equal')\n",
    "    \n",
    "x = show_projection(a,b) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<a name=\"Gram-Schmidt_Orthoganalization_Process\"></a>\n",
    "\n",
    "# 3. Gram-Schmidt Orthoganalization Process\n",
    "\n",
    "&#9989; **<font color=red>DO THIS:</font>** Implement the Gram-Schmidt orthoganalization process from the [Hefron](http://joshua.smcvt.edu/linearalgebra/book.pdf) textbook (page 282). \n",
    "This function takes a $m \\times n$ Matrix $A$ with linearly independent columns as input and return a $m \\times n$ Matrix $G$ with orthogonal column vectors. \n",
    "The basic algorithm works as follows:\n",
    "\n",
    "- ```AT = transpose(A)``` (this process works with the columns of the matrix so it is easier to work with the transpose. Think about a list of list, it is easy to get a row (a list)).  \n",
    "- Make a new empty list of the same size as ```AT``` and call it ```GT``` (G transpose)\n",
    "- Loop index ```i``` over all of the rows in AT (i.e. columns of A) \n",
    "\n",
    "    - ```GT[i] = AT[i]```\n",
    "    - Loop index ```j``` from 0 to ```i```\n",
    "        - ```GT[i] -= proj(GT[i], GT[j])```\n",
    "        \n",
    "        \n",
    "- ```G = transpose(GT)```\n",
    "\n",
    "Use the following function definition as a template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GramSchmidt(A):\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to test your function using the vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A4 = [[1,4,8],[2,0,1],[0,5,5],[3,8,6]]\n",
    "print(transpose(A4))\n",
    "G4 = GramSchmidt(A4)\n",
    "print(transpose(G4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "\n",
    "checkanswer.matrix(G4,'a472a81eef411c0df03ae9a072dfa040');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = [[-4,-6],[3,5]]\n",
    "print(transpose(A2))\n",
    "G2 = GramSchmidt(A2)\n",
    "print(transpose(G2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "\n",
    "checkanswer.matrix(G2,'23b9860b72dbe5b84d7c598c08af9688');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "<a name ='subspace'></a>\n",
    "## 4. Subspace Projections\n",
    "\n",
    "The following is the matimatical defination of projection onto a subspace.\n",
    "\n",
    "**Definition**: Let $W$ be a subspace of $R^n$ of dimension $m$. Let $\\{w_1,\\cdots,w_m\\}$ be an orthogonal basis for $W$. Then the projection of vector $v$ in $R^n$ onto $W$ is denoted as $\\mbox{proj}_Wv$ and is defined as the sum of the projections onto the basis vectors for $W$:\n",
    "\n",
    "$$\\mbox{proj}_Wv = \\mbox{proj}_{w_1} v + \\dots + \\mbox{proj}_{w_n} v\\\\\n",
    "= \\frac{(v\\cdot w_1)}{(w_1\\cdot w_1)}w_1+\\frac{(v\\cdot w_2)}{(w_2\\cdot w_2)}w_2+\\cdots+\\frac{(v\\cdot w_m)}{(w_m\\cdot w_m)}w_m$$\n",
    "\n",
    "\n",
    "Another way to say the above definition is that the project of $v$ onto the $W$ is just the sumation of $v$ projected onto each vector in a basis of $W$\n",
    "\n",
    "\n",
    "**Remarks**: \n",
    "> Recall in the lecture on *Projections*, we discussed the projection onto a vector, which is the case for $m=1$. We used the projection for $m>1$ in the Gram-Schmidt algorithm. \n",
    "\n",
    "> The projection does not depend on which orthogonal basis you choose. \n",
    "\n",
    "> If $v$ is in $W$, we have $\\mbox{proj}_Wv=v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sym\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "sym.init_printing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** Let $v=(3, 2, 6)$ and $W$ is the subspace consisting all vectors with the form $(a, b, b)$. Find the projection of $v$ onto $W$. That is find $w = \\mbox{proj}_W v$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.vector(w,'13404b60fa3f349ae3982b2587048040')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'orthog_decomp'></a>\n",
    "## 5. The Orthogonal Decomposition Theorem\n",
    "**Theorem**: Let $W$ be a subspace of $R^n$. Every vector $v$ in $R^n$ can be written uniquely in the form \n",
    "$$v= w+w_{\\bot},$$\n",
    "where $w$ is in $W$ and $w_\\bot$ is orthogonal to $W$ (i.e., $w_\\bot$ is in $W_\\bot$). \n",
    "In addition, $w=\\mbox{proj}_Wv$, and $w_\\bot = v-\\mbox{proj}_Wv$.\n",
    "\n",
    "**Definition**: Let $x$ be a point in $R^n$, $W$ be a subspace of $R^n$. The distance from $x$ to $W$ is defined to be the minimum of the distances from $x$ to any point $y$ in $W$.\n",
    "$$d(x,W)=\\min \\{\\|x-y\\|: \\mbox{ for all }y \\mbox{ in } W\\}.$$\n",
    "The optimal $y$ can be achieved at $\\mbox{proj}_Wx$, and $d(x,W)=\\|x-\\mbox{proj}_Wx\\| = \\| x_\\bot \\|$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** Let $v=(3, 2, 6)$ and $W$ is the subspace consisting all vectors with the form $(a, b, b)$. Find the distance from $v$ to $W$.\n",
    "\n",
    "**Hint.** Your answer from the previous question will be very helpful to this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##work here\n",
    "\n",
    "# dist = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.float(dist,'f8f24a9cedb159fc084bc4e6e347dc07')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n",
    "<a name='innerP'></a>\n",
    "## 6. Inner Products and Matrices\n",
    "\n",
    "The following is a review from the pre-class assignment.\n",
    "\n",
    "An inner product on a real vector space $V$ is a function that associates a number, denoted as $\\langle u,v \\rangle$, with each pair of vectors $u$ and $v$ of $V$. This function satisfies the following conditions for vectors $u, v, w$ and scalar $c$:\n",
    "\n",
    "\n",
    "$$\\langle u,v \\rangle = \\langle v,u \\rangle \\text{ Symmetry axiom}$$ \n",
    "\n",
    "$$\\langle u+v,w \\rangle = \\langle u,w \\rangle + \\langle v,w \\rangle \\text{ Additive axiom}$$ \n",
    "\n",
    "$$\\langle cu,v \\rangle = c\\langle v,u \\rangle \\text{ Homogeneity axiom}$$ \n",
    "\n",
    "$$\\langle u,u \\rangle \\ge 0 \\text{ and } \\langle u,u \\rangle = 0 \\text{ if and only if } u = 0 \\text{ Positive definite axiom}$$ \n",
    "\n",
    "\n",
    "The dot product of $R^n$ is an inner product. However, we can define many other inner products.\n",
    "\n",
    "Notice that the dot product of two column vectors $u= \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix}$ and $v= \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}$ can also be written as a matrix multiplication \n",
    "\n",
    "$$u \\cdot v = u_1v_1 + u_2v_2 = u^\\top * v$$\n",
    "\n",
    "Now imagine that there is an identity matrix in the middle of the matrix product and we have \n",
    "$u \\cdot v = u^\\top Iv$. This exmplifies a fundamental relationship between inner products and matrices.\n",
    "\n",
    "Now notice for an arbitary matrix $A = \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{bmatrix}$ we have \n",
    "\n",
    "$$ u^\\top A v = a_{11} u_1v_1 + a_{12}u_1v_2 + a_{21}u_2v_1 + a_{22}u_2v_2$$ which looks an awful lot like a formula for an inner product. Definining the function $f(u,v) = u^\\top A v$ guarentees that it satisfies the additive and homogeneity axiom for inner products. We need a matrix way to represent the other two axioms for inner products.\n",
    "\n",
    "**Definition.** A square matrix is said to be positive definite if all of its eigenvalues are positive.\n",
    "\n",
    "**Definition** A matrix $A$ is said to be symmetric if $a_{ij} = a_{ji}$ for all entries of the matrix.\n",
    "\n",
    "**Definition.** An $n \\times n$ matrix $A$ defines an inner product on $R^n$ by the formula $$ \\langle u,v \\rangle = u^\\top A v$$ if and only if the matrix $A$ is positive definite and symmetric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do This:</font>** Show that the matrix $$ A = \\begin{bmatrix} 3 & -1 \\\\ -1 & 2 \\end{bmatrix}$$ is positive definite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##your work here\n",
    "A = np.matrix('3,-1;-1,2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** Does the matrix $A$ given above represent an inner product on $R^2$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>QUESTION:</font>** Find the matrix representing the inner product\n",
    "\n",
    "$$\\langle u,v \\rangle = 6u_1v_1 -2 u_1v_2 -2 u_2 v_1 +4 u_2 v_2 $$ \n",
    "\n",
    "and use it to compute the norm of the vector $ v = [1,-2].$\n",
    "\n",
    "**Hint.** Double check the pre-class assignment for the formula for norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.float(norm,'afcf64b47c2dc5ae8e86701f0cbd5eb9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Function_Approximation\"></a>\n",
    "## 7. Function Approximation\n",
    "\n",
    "**Definition:** Let $C[a,b]$ be a vector space of all possible continuous functions over the interval $[a,b]$ with inner product:\n",
    "$$\\langle f,g \\rangle = \\int_a^b f(x)g(x) dx.$$\n",
    "\n",
    "\n",
    "\n",
    "Now let $f$ be an element of $C[a,b]$, and $W$ be a subspace of $C[a,b]$. The function $g \\in W$ such that the distance \n",
    "\n",
    "$$d(f,g) = \\sqrt{\\langle f-g, f-g \\rangle} = \\int_a^b \\left[ f(x) - g(x) \\right]^2 dx$$ \n",
    "\n",
    "is a minimum is called the **least-squares approximation** to $f$.\n",
    "\n",
    "\n",
    "As stated in the \"The Orthogonal Decomposition Theorem\" section of this notebook The least-squares approximation to $f$ in the subspace $W$ can be calculated as the projection of $f$ onto $W$, $g = proj_Wf$. Like in the \"Subspace Projections\" section if we rewrite the formula using an arbitary inner product in lieu of the dot product we have the following:\n",
    "\n",
    "If $\\{g_1, \\ldots, g_n\\}$ is an orthogonal basis for $W$, we have \n",
    "\n",
    " $$prog_Wf = \\frac{\\langle f,g_1 \\rangle}{\\langle g_1,g_1 \\rangle} g_1 + \\dots + \\frac{\\langle f,g_n \\rangle}{\\langle g_n,g_n\n",
    " \\rangle} g_n$$\n",
    " \n",
    " \n",
    "###  Polynomial Approximations\n",
    "\n",
    "An orthogonal bases for all polynomials of degree less than or equal to $n$ can be computed using Gram-schmidt orthogonalization process.  First we start with the following standard basis vectors in $W$\n",
    "\n",
    "$$ \\{ 1, x, \\ldots, x^n \\}$$\n",
    "\n",
    "The Gram-Schmidt process can be used to make these vectors orthogonal. The resulting polynomials on $[-1,1]$ are called  **Legendre polynomials**.  The first six Legendre polynomial basis elements are:\n",
    "\n",
    "$$1$$\n",
    "$$x$$\n",
    "$$x^2 -\\frac{1}{3}$$\n",
    "$$x^3 - \\frac{3}{5}x$$\n",
    "$$x^4 - \\frac{6}{7}x^2 + \\frac{3}{35}$$\n",
    "$$x^5 - \\frac{10}{9}x^3 + \\frac{5}{12}x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;**<font color=red>QUESTION:**</font> What is the least-squares linear approximations of $f(x) = e^x$ over the interval $[-1, 1]$. In other words, what is the projection of $f$ onto $W$, where $W$ is a first order polynomal with basis vectors $\\{1, x\\} (i.e. n=1)$. \n",
    "\n",
    "**Hint.** You can give the answer in integrals without computing the integrals. Note the Legendre polynomials are not normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a plot of the equation $f(x) = e^x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "#px = np.linspace(-1,1,100)\n",
    "#py = np.exp(px)\n",
    "#plt.plot(px,py, color='red');\n",
    "import sympy as sym\n",
    "from sympy.plotting import plot\n",
    "x = sym.symbols('x')\n",
    "f = sym.exp(x)\n",
    "plot(f,(x,-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `sympy` to compute the integral. The following code compute the definite integral of \n",
    "$$\\int_{-1}^1 e^x dx.$$\n",
    "In fact, `sympy` can also compute the indefinite integral by removing the interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym.init_printing()\n",
    "x = sym.symbols('x')\n",
    "sym.integrate('exp(x)',(x, -1, 1))\n",
    "#sym.integrate('exp(x)',(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sympy` to compute the first order polynomial that approximates the function $e^x$.\n",
    "The following calculates the above approximation written in ```sympy```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_0 = sym.integrate('exp(x)*1',(x, -1, 1))/sym.integrate('1*1',(x,-1,1))*1\n",
    "g_1 = g_0 + sym.integrate('exp(x)*x',(x,-1,1))/sym.integrate('x*x',(x,-1,1))*x\n",
    "g_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the original function $f(x)=e^x$ and its approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = plot(f, g_1,(x,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For fun, I turned this into a function:\n",
    "x = sym.symbols('x')\n",
    "\n",
    "def lsf_poly(f, gb = [1,  x], a =-1, b=1):\n",
    "    proj = 0\n",
    "    for g in gb:\n",
    "#        print(sym.integrate(g*f,(x,a,b)))\n",
    "        proj = proj + sym.integrate(g*f,(x,a,b))/sym.integrate(g*g,(x,a,b))*g\n",
    "    return proj\n",
    "\n",
    "lsf_poly(sym.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;**<font color=red>QUESTION:</font>** What would a second order approximation look like for this function? How about a fifth order approximation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your answer to the above question here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sym.symbols('x')\n",
    "g_2 = \n",
    "g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = plot(f, g_2,(x,-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
